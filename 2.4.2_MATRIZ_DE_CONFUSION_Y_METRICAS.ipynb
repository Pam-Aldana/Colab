{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["***\n","BASADO EN https://github.com/Lawrence-Krukrubo/Machine_Learning\n","***\n"],"metadata":{"id":"PLErrxjpURqS"}},{"cell_type":"code","metadata":{"id":"iDhT4fAxgOzZ"},"source":["print(__doc__)\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import itertools\n","from sklearn.metrics import roc_curve, auc\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K4MzCNjgh2W0"},"source":["Importemos su conjunto de datos  y creemos un dataframe en Pandas"]},{"cell_type":"code","metadata":{"id":"CuVVGqibiAwq"},"source":["data_link = 'sample_data/diabetes.csv'\n","\n","diabetes_df = pd.read_csv(data_link)\n","\n","diabetes_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wy36kU00ijM8"},"source":["Verifiquemos la forma y si existen valores faltantes."]},{"cell_type":"code","metadata":{"id":"fD2ShA1Qin4x"},"source":["diabetes_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CrAm8bWLiqro","outputId":"d040dd34-d3c3-4d86-eee7-8adbcf80763e","colab":{"base_uri":"https://localhost:8080/"}},"source":["diabetes_df.isna().any()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PatientID                 False\n","Pregnancies               False\n","PlasmaGlucose             False\n","DiastolicBloodPressure    False\n","TricepsThickness          False\n","SerumInsulin              False\n","BMI                       False\n","DiabetesPedigree          False\n","Age                       False\n","Diabetic                  False\n","dtype: bool"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"5PlahZq0mYx_"},"source":["Veamos la distribución de cada columna, esto nos ayudaría a elegir el método de normalización de características más ideal.<br>\n","Primero, definamos un método que represente la distribución de cada característica."]},{"cell_type":"code","metadata":{"id":"wVySOHK8msHN"},"source":["def plot_features(data):\n","    plt.figure(figsize=(20, 10))\n","    sns.set(font_scale=1.2)\n","    sns.set_style('ticks') # change background to white background\n","    plt.suptitle('Visualizing The Features Distribution', y=0.95)\n","\n","    plt.subplot(241)\n","    color_list = ['gold','purple','brown']\n","    data.Age.plot(kind='hist', color='brown')\n","    plt.xlabel('Age')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(242)\n","    color_list = ['gold','purple','brown']\n","    data.Pregnancies.plot(kind='hist', color='brown')\n","    plt.xlabel('Pregnancies')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(243)\n","    color_list = ['gold','purple','brown']\n","    data.PlasmaGlucose.plot(kind='hist', color='brown')\n","    plt.xlabel('PlasmaGlucose')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(244)\n","    color_list = ['gold','purple','brown']\n","    data.DiastolicBloodPressure.plot(kind='hist', color='brown')\n","    plt.xlabel('DiastolicBP')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(245)\n","    color_list = ['gold','purple','brown']\n","    data.TricepsThickness.plot(kind='hist', color='brown')\n","    plt.xlabel('TricepsThickness')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(246)\n","    color_list = ['gold','purple','brown']\n","    data.SerumInsulin.plot(kind='hist', color='brown')\n","    plt.xlabel('SerumInsulin')\n","    plt.ylabel('Frequency')\n","\n","\n","    plt.subplot(247)\n","    color_list = ['gold','purple','brown']\n","    data.BMI.plot(kind='hist', color='brown')\n","    plt.xlabel('BMI')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(248)\n","    color_list = ['gold','purple','brown']\n","    data.DiabetesPedigree.plot(kind='hist', color='brown')\n","    plt.xlabel('DiabetesPedigree')\n","    plt.ylabel('Frequency')\n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4PlJMg7JAsP"},"source":["plot_features(diabetes_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eWkfoi6FF7AG"},"source":["Podemos ver que características como Edad, DiabetesPedigree, SerumInsulin e IMC parecen estar sesgadas hacia la derecha.<br>\n","Esto se debe a una gran cantidad de valores más pequeños y a una distribución progresiva de menos valores grandes.<br>\n","Mejoremos la distribución usando el registro de los valores, en lugar de los valores reales en estas características.<br>\n","Esta es una parte del proceso de ingeniería de características en Machine Learning"]},{"cell_type":"code","metadata":{"id":"B1uy0emlF5kY"},"source":["for i in diabetes_df.columns:\n","    if i in ['Age', 'DiabetesPedigree', 'BMI', 'SerumInsulin']:\n","        print(i)\n","        diabetes_df[i] = diabetes_df[i].apply(np.log)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7wgOV2tyLJjQ"},"source":["Veamos la distribución de nuevo."]},{"cell_type":"code","metadata":{"id":"t4bVNsQRJjEz"},"source":["plot_features(diabetes_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qYiYg3NkLN3c"},"source":["De los gráficos anteriores, podemos ver una mejora en la distribución de nuestras características.<br>\n","Esto nos ayudaría a lograr un mejor resultado cuando entrenamos el modelo."]},{"cell_type":"markdown","source":["***\n","EJERCICIO : ¿Por qué tendremos un mejor resultado si cambiamos la distribución de los datos?\n","***"],"metadata":{"id":"pvMwafxigSww"}},{"cell_type":"markdown","metadata":{"id":"7vXTDeo5mDGQ"},"source":["Bien, ahora veamos el conjunto de datos que contiene los nombres de los médicos que tratan a nuestros respectivos pacientes.\n","Lo cargamos en un dataframe."]},{"cell_type":"code","metadata":{"id":"K0J90XTBs0JW"},"source":["doctors_link = 'sample_data/doctors.csv'\n","\n","doctors_df = pd.read_csv(doctors_link, encoding='latin-1')\n","\n","doctors_df.head()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RG01OWeTs_rr"},"source":["doctors_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_SlFJ3NsoHX-"},"source":["doctors_df.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jPIhFJE-pU7C"},"source":["Entonces podemos ver que los datos del Doctor son ligeramente más pequeños que el conjunto de datos de los pacientes.<br>\n","Esto puede deberse al hecho de que algunos médicos vieron a más de un paciente.<br>\n","\n","***\n"," EJERCICIO : una ambas tablas. Debe tener cuidado de no perder pacientes (fíjese si la unión es por izquierda o derecha).\n","***"]},{"cell_type":"code","metadata":{"id":"lw7IvlJCpNxu"},"source":["#diabetes_doctor_df = ...COLOQUE SU CÓDIGO AQUI\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKUdBM_wtMlE"},"source":["Ahora podemos ver la columna de médicos adjunta y podemos decir qué médico trató a un paciente.<br>\n","Veamos la forma y también verifiquemos el número y las columnas con valores nulos"]},{"cell_type":"code","metadata":{"id":"DZoyhLr5tnCh","outputId":"6f74c7f5-28de-4d32-83fe-625412545843","colab":{"base_uri":"https://localhost:8080/"}},"source":["diabetes_doctor_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15000, 11)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"WVrVwD_nt0DE"},"source":["diabetes_doctor_df.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QZUqsBVhtiCp"},"source":["Verifiquemos la cantidad de médicos únicos en la lista de médicos"]},{"cell_type":"code","metadata":{"id":"lX_Pxqw2tHL8"},"source":["diabetes_doctor_df.Physician.nunique()\n","\n","# Deberá tener 109 doctores que han tratado a 15.000 pacientes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xscYfjYC0LsS"},"source":["Verifiquemos también la cantidad de pacientes únicos en el conjunto de datos"]},{"cell_type":"code","metadata":{"id":"k_5RIFmWz78a"},"source":["diabetes_doctor_df.PatientID.nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VtylrfUE0ZEB"},"source":["Ahora tiene sentido,<br>\n","Hay 14895 pacientes únicos y los registros médicos tienen entradas para exactamente 14895 pacientes.<br>\n","El hecho de que el conjunto de datos de los pacientes tenga 15000 entradas se debe simplemente a que algunos pacientes tenían varias entradas.<br>\n","Dado que fusionamos los médicos y los pacientes en la columna de ID de paciente, la fusión asigna correctamente a cada médico a los pacientes que trató, aunque solo tenemos 109 médicos únicos."]},{"cell_type":"code","metadata":{"id":"LQ3LCTeHujMP"},"source":["diabetes_doctor_df.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DqesEjlvwu7o"},"source":["### Preparación de datos"]},{"cell_type":"markdown","metadata":{"id":"fcBhfmN8w6Bf"},"source":["Como suele ser el caso con el aprendizaje automático de cualquier tipo, se requiere cierta preparación de datos antes de poder\n","use los datos para entrenar un modelo.<br>\n","Normalizaremos las características para que las características que tienen valores grandes no dominen el entrenamiento.<br>\n","Al observar las formas de la distribución de cada característica, aquellas con una forma de campana de distribución más o menos normal se normalizarán mediante el método Zscore.<br>\n","Mientras que aquellos con valores grandes y bajos variables se normalizarán utilizando el método Min-Max."]},{"cell_type":"markdown","metadata":{"id":"LRNm0Ccq3YKH"},"source":["**1. Z-Score or Standard Score**_  \n","  \n","\n","$Xnew =$ $Xold - mean \\over STD(sigma)$"]},{"cell_type":"markdown","metadata":{"id":"bSw1UjuF3gEq"},"source":["_**2. Min-Max Method**_  \n","\n","\n","$Xnew =$ $Xold - Xmin \\over Xmax - Xmin$"]},{"cell_type":"markdown","metadata":{"id":"kokc-lzf4Lj2"},"source":["***\n","EJERCICIO : Ahora apliquemos estos métodos a las columnas seleccionadas usando el método adecuado.\n","***"]},{"cell_type":"code","metadata":{"id":"dH-o3IJ04bDf"},"source":["for i in diabetes_doctor_df.columns[:-2]:\n","    mean = diabetes_doctor_df[i].mean()\n","    std = diabetes_doctor_df[i].std()\n","    mini = diabetes_doctor_df[i].min()\n","    maxi = diabetes_doctor_df[i].max()\n","\n","    # if columns are not Age or Pregnancies, apply the Z_score norm method\n","    #\n","    if i not in ['Age', 'Pregnancies']:\n","     # COLOQUE SU CODIGO NORMALIZACION AQUI\n","    # Else if columns are either Age or Pregnancies, then apply the Min-Max norm method\n","    else:\n","        # COLOQUE SU CODIGO AQUI\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bYPtSab0OWPf"},"source":["diabetes_doctor_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"glrVj-wWQ9Wk"},"source":["Ahora que hemos preparado el conjunto de datos, lo usaremos para entrenar y evaluar una máquina clasificadora.\n","modelo de aprendizaje Por lo general, cuando se entrena un modelo de aprendizaje supervisado, en el que los datos de entrenamiento incluyen\n","valores de etiqueta conocidos, dividimos los datos en un conjunto de entrenamiento con el que entrenar el modelo y un conjunto de prueba\n","con el que validar las predicciones generadas por el modelo entrenado."]},{"cell_type":"markdown","metadata":{"id":"3SXwGGcBEJl8"},"source":["Antes de continuar, verifiquemos la cantidad de observaciones que tiene cada clase de diabéticos o no diabéticos<br>"]},{"cell_type":"code","metadata":{"id":"3TTEkwcmD48w"},"source":["diabetes_doctor_df.Diabetic.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2nkD1PnqFMTz"},"source":["Visualizemos la distribución"]},{"cell_type":"code","metadata":{"id":"u-xqbIxEFKI_"},"source":["plt.figure(figsize=(6, 6))\n","\n","sns.countplot(x=diabetes_doctor_df[\"Diabetic\"])\n","plt.title('Count of Diabetics and Non-Diabetics')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6AJqd9wDTnjP"},"source":["Podemos ver que de las 15 000 observaciones en nuestro conjunto de datos, la clase No diabético tiene 10 000 entradas, mientras que la clase Diabético tiene solo 5000 entradas.<br>\n","Este es un conjunto de datos DESEQUILIBRADO y el riesgo que implica es que nuestro modelo puede aprender las características de una clase más que la otra.<br>\n","Necesitamos encontrar una manera de equilibrar el conjunto de datos para una clasificación más imparcial y confiable."]},{"cell_type":"markdown","metadata":{"id":"8f6vQ7rDTjTx"},"source":["Antes de hacer la división, seleccionemos solo las columnas que importan anulando las columnas ID del paciente y Médico."]},{"cell_type":"markdown","source":["***\n","EJERCICIO : elimine las columnas indicadas\n","****"],"metadata":{"id":"emVthL0eiZ-7"}},{"cell_type":"code","metadata":{"id":"Sbh6IhSqQ8IH"},"source":["# COLOQUE SU CODIGO AQUI\n","feature_matrix.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kAOjoX3rluz6"},"source":["definamos también nuestra variable de etiqueta"]},{"cell_type":"markdown","source":["***\n","EJERCICIO : ASIGNE LA COLUMNA CON LA ETIQUETA\n","***"],"metadata":{"id":"uHPzubwBiqTx"}},{"cell_type":"code","metadata":{"id":"ghv9W1Spl6hn"},"source":["#label = COLOQUE SU CODIGO AQUI\n","\n","label.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lbi9YdKRTzjO"},"source":["feature_matrix.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0C42ux8TUKDG"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(feature_matrix, label, test_size=0.3, random_state=1234)\n","\n","print('X_train shape is',X_train.shape)\n","print('X_test shape is',X_test.shape)\n","print('y_train shape is',y_train.shape)\n","print('y_test shape is',y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z1DZRrpgm-O1"},"source":["Creamos Decision Tree Classifier"]},{"cell_type":"code","metadata":{"id":"Wt-xORLlpYHv"},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn import metrics\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import log_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoGU06nCqMGw"},"source":["Definimos una función para imprimir la Confusion-Matrix"]},{"cell_type":"code","metadata":{"id":"D_i2i663qSyn"},"source":["from sklearn.metrics import classification_report\n","\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qSrj-S1Fqc-B"},"source":["Definamos una función que devuelva el mejor modelo clasificador de árbol de decisión y genere sus parámetros y un gráfico de la matriz de confusión."]},{"cell_type":"code","metadata":{"id":"bRlK5jEBJ4Ng"},"source":["# set max depth range limit for DTree model to iterate through from 1 to 100 to find best parameters\n","\n","\n","def best_decision_tree_classifier(X_train, X_test, y_train, y_test):\n","    max_depth = 100\n","    accuracy_dict={'max_depth':0, 'val_acc':0, 'f1_Score':0, 'log_loss':0}\n","\n","    for i in range(1, max_depth+1):\n","            # Let's instantiate a model\n","            decision_model = DecisionTreeClassifier(criterion='entropy', max_depth = i)\n","\n","            # Let's train the model\n","            decision_model.fit(X_train, y_train)\n","\n","            # Let's make prediction on the test data\n","            y_hat = decision_model.predict(X_test)\n","\n","            # Let's measure accuracy of predictions on test data\n","            val_accu = round(metrics.accuracy_score(y_test, y_hat),4)\n","\n","            # Let's Measure the F1 Score\n","            val_f1 = round(f1_score(y_test, y_hat, average='weighted'),4)\n","\n","            # Let's Measure Logloss\n","            logloss = round(log_loss(y_test, y_hat, normalize=True),4)\n","\n","            if accuracy_dict['val_acc'] < val_accu or accuracy_dict['f1_Score'] < val_f1:\n","                accuracy_dict['max_depth'] = i\n","                accuracy_dict['val_acc'] = val_accu\n","                accuracy_dict['f1_Score'] = val_f1\n","                accuracy_dict['log_loss'] = logloss\n","                decision_model = decision_model\n","\n","            # Compute confusion matrix\n","            Dtrees_cnf_matrix = confusion_matrix(y_test, y_hat, labels=[1,0])\n","            np.set_printoptions(precision=2)\n","\n","            TP = Dtrees_cnf_matrix[0,0]\n","            FP = Dtrees_cnf_matrix[0,1]\n","            FN = Dtrees_cnf_matrix[1,0]\n","            TN = Dtrees_cnf_matrix[1,1]\n","\n","            accuracy = (TP + TN) / (TP + TN + FP + FN)\n","            recall = TP / (TP + FN)\n","            precision = TP / (TP + FP)\n","\n","    # Plot non-normalized confusion matrix\n","    plt.figure(figsize=(10, 6))\n","    sns.set(font_scale=1.3)\n","    plot_confusion_matrix(Dtrees_cnf_matrix,\n","                          classes=['Default=1','Non-Default=0'],\n","                          normalize= False,\n","                          title='Confusion Matrix for Decision-Tree-Classifier')\n","    plt.show()\n","    print()\n","\n","    print('TP is:',TP,'FP is:',FP,'TN is:',TN,'FN is:',FN)\n","    print()\n","    print('Model Evaluation:')\n","    print(accuracy_dict)\n","    print()\n","    #plot_roc_chart(decision_model)\n","    print()\n","    print('accuracy is:',round(accuracy,2))\n","    print('recall is:',round(recall,2))\n","    print('precision is:',round(precision,2))\n","    print()\n","\n","    return decision_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZzLQQN1hkrC"},"source":["decision_tree_classifier = best_decision_tree_classifier(X_train, X_test, y_train, y_test)\n","decision_tree_classifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D3gG2D7wqgw3"},"source":["##Notas"]},{"cell_type":"markdown","metadata":{"id":"5e0gNw2ah8rz"},"source":["Tenga en cuenta lo siguiente sobre estas métricas:<br>\n","• La Matriz de Confusión muestra el número de Verdaderos Positivos y Verdaderos Negativos (casos\n","correctamente clasificados) y Falsos Negativos y Falsos Positivos (casos incorrectamente clasificados).<br>\n","\n","• Accuracy es la fracción de casos clasificados correctamente.<br>\n","• Recall, es la fracción de casos positivos clasificados correctamente del total de casos positivos en el conjunto de datos. <br>\n","• Precision es la fracción de casos positivos clasificados correctamente de todos los casos clasificados como positivos."]},{"cell_type":"markdown","source":["****\n","EJERCICIO:\n","\n","1.   Comente los valores de la métricas\n","2.   ¿Cuál es el efecto que produce en ellas que los datos estén DESBALANCEADOS?\n","3.   ¿Cuál es el valor de F1 SCORE?\n","\n","*****\n"],"metadata":{"id":"J2LoMtORjBQd"}}]}